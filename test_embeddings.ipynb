{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from pymongo import MongoClient\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import (\n",
    "    NMF,\n",
    "    SVD,\n",
    "    BaselineOnly,\n",
    "    CoClustering,\n",
    "    Dataset,\n",
    "    KNNBaseline,\n",
    "    KNNBasic,\n",
    "    KNNWithMeans,\n",
    "    KNNWithZScore,\n",
    "    NormalPredictor,\n",
    "    Reader,\n",
    "    SlopeOne,\n",
    "    SVDpp,\n",
    "    accuracy,\n",
    ")\n",
    "from surprise.model_selection import GridSearchCV, KFold, cross_validate\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_URI = os.getenv(\"MONGO_URI\")\n",
    "PINECONE_API_KEY = os.environ.get(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"recommender-system\"\n",
    "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
    "gpt4all_kwargs = {\"allow_download\": \"True\"}\n",
    "model_path = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "RANDOM_STATE = 101\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "MLFLOW_EXPERIMENT_NAME = os.getenv(\"MLFLOW_EXPERIMENT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = MongoClient(MONGO_URI)\n",
    "db = connection[\"shein-mirror\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = db[\"product_reviews\"]\n",
    "data = pd.DataFrame(list(input_data.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_pipeline = pipeline(\n",
    "    \"sentiment-analysis\", model=model_path, tokenizer=model_path, device=\"mps\", batch_size=8, truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sentiment_pipeline(data[\"review\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"] = [int(r[\"label\"][0:1]) for r in res]\n",
    "data[\"sentiment_score\"] = [r[\"score\"] for r in res]\n",
    "data[\"rating_from_score\"] = np.round(data[\"sentiment_score\"] * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sentiment\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating_from_score\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_parquet(\"data/processed/reviews.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"data/processed/reviews.parquet\", engine=\"pyarrow\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"] = data[\"sentiment\"].apply(lambda x: int(x[0:1]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "db[\"product_reviews-mirror\"].drop()\n",
    "db[\"product_reviews-mirror\"].insert_many(data.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"nickname\", \"product_id\", \"sentiment\"]]\n",
    "data = data.rename(columns={\"nickname\": \"userID\", \"product_id\": \"itemID\", \"sentiment\": \"rating\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rating\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = list(data[\"userID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = list(data[\"itemID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.3, random_state=RANDOM_STATE, stratify=data[[\"rating\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1, 5))\n",
    "data_sp = Dataset.load_from_df(data, reader=reader)\n",
    "train_sp = Dataset.load_from_df(train, reader=reader)\n",
    "test_sp = Dataset.load_from_df(test, reader=reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = train_sp.build_full_trainset()\n",
    "testset = test_sp.build_full_trainset().build_testset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = [\n",
    "    SVD(random_state=RANDOM_STATE),\n",
    "    BaselineOnly(),\n",
    "    CoClustering(),\n",
    "    KNNBaseline(),\n",
    "    KNNWithZScore(),\n",
    "    KNNWithMeans(),\n",
    "    SlopeOne(),\n",
    "    KNNBasic(),\n",
    "    NormalPredictor(),\n",
    "    NMF(random_state=RANDOM_STATE),\n",
    "    SVDpp(random_state=RANDOM_STATE),\n",
    "]\n",
    "names = [algo[i].__class__.__name__ for i in range(len(algo))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {names[i]: {\"algo\": algo[i]} for i in range(len(algo))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.zeros((len(names), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Default parameters\") as run:\n",
    "    experiment_id = run.info.experiment_id\n",
    "    for k, v in algos.items():\n",
    "        with mlflow.start_run(experiment_id=experiment_id, run_name=k, nested=True) as subruns:\n",
    "            tab = cross_validate(v[\"algo\"], data_sp, cv=5, verbose=True, n_jobs=-1)\n",
    "            v[\"test_RMSE\"] = tab[\"test_rmse\"]\n",
    "            v[\"test_mae\"] = tab[\"test_mae\"]\n",
    "            v[\"fit_time\"] = tab[\"fit_time\"]\n",
    "            v[\"test_time\"] = tab[\"test_time\"]\n",
    "\n",
    "            rmse = np.mean(tab[\"test_rmse\"])\n",
    "            mae = np.mean(tab[\"test_mae\"])\n",
    "            ft = np.mean(tab[\"fit_time\"])\n",
    "            tt = np.mean(tab[\"test_time\"])\n",
    "\n",
    "            mlflow.log_metrics({\"rmse_test\": rmse, \"mae_test\": mae, \"fit_time\": ft, \"test_time\": tt})\n",
    "            mlflow.sklearn.log_model(v[\"algo\"], k)\n",
    "\n",
    "            result[algo.index(v[\"algo\"])] = [rmse, mae, ft, tt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for k, v in algos.items():\n",
    "    plt.boxplot(\n",
    "        v[\"test_RMSE\"],\n",
    "        positions=[list(algos.keys()).index(k)],\n",
    "        widths=0.6,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(\n",
    "            facecolor=\"C\" + str(list(algos.keys()).index(k)), color=\"C\" + str(list(algos.keys()).index(k)), linewidth=2\n",
    "        ),\n",
    "    )\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xticks(range(len(algos)), list(algos.keys()), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for k, v in algos.items():\n",
    "    plt.boxplot(\n",
    "        v[\"test_mae\"],\n",
    "        positions=[list(algos.keys()).index(k)],\n",
    "        widths=0.6,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(\n",
    "            facecolor=\"C\" + str(list(algos.keys()).index(k)), color=\"C\" + str(list(algos.keys()).index(k)), linewidth=2\n",
    "        ),\n",
    "    )\n",
    "plt.ylabel(\"MAE\")\n",
    "plt.xticks(range(len(algos)), list(algos.keys()), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for k, v in algos.items():\n",
    "    plt.boxplot(\n",
    "        v[\"fit_time\"],\n",
    "        positions=[list(algos.keys()).index(k)],\n",
    "        widths=0.6,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(\n",
    "            facecolor=\"C\" + str(list(algos.keys()).index(k)), color=\"C\" + str(list(algos.keys()).index(k)), linewidth=2\n",
    "        ),\n",
    "    )\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.xticks(range(len(algos)), list(algos.keys()), rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for k, v in algos.items():\n",
    "    plt.boxplot(\n",
    "        v[\"test_time\"],\n",
    "        positions=[list(algos.keys()).index(k)],\n",
    "        widths=0.6,\n",
    "        patch_artist=True,\n",
    "        boxprops=dict(\n",
    "            facecolor=\"C\" + str(list(algos.keys()).index(k)), color=\"C\" + str(list(algos.keys()).index(k)), linewidth=2\n",
    "        ),\n",
    "    )\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.xticks(range(len(algos)), list(algos.keys()), rotation=45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.round(3)\n",
    "result = pd.DataFrame(result, index=list(algos.keys()), columns=[\"RMSE\", \"MAE\", \"fit_time\", \"test_time\"])\n",
    "result = result.sort_values(by=\"RMSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(result, annot=True, linecolor=\"w\", linewidth=2, cmap=sns.color_palette(\"Blues\"))\n",
    "plt.title(\"Data summary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svd = {\n",
    "    \"n_epochs\": [5, 10, 20],\n",
    "    \"lr_all\": [0.002, 0.005],\n",
    "    \"reg_all\": [0.4, 0.6],\n",
    "    \"n_factors\": [15, 30, 100],\n",
    "    \"random_state\": [RANDOM_STATE],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_bso = {\"bsl_options\": {\"method\": [\"als\", \"sgd\"], \"n_epochs\": [5, 15], \"reg_u\": [10, 20], \"reg_i\": [5, 15]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = {\n",
    "    \"SVD\": {\"algo\": SVD, \"params\": param_grid_svd},\n",
    "    \"BaselineOnly\": {\"algo\": BaselineOnly, \"params\": param_grid_bso},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Fine-tuned-selected\") as run:\n",
    "    experiment_id = run.info.experiment_id\n",
    "    for k, v in algos.items():\n",
    "        print(k)\n",
    "        with mlflow.start_run(experiment_id=experiment_id, run_name=k, nested=True) as subruns:\n",
    "            gs = GridSearchCV(v[\"algo\"], v[\"params\"], measures=[\"rmse\", \"mae\"], cv=5, n_jobs=-1)\n",
    "            gs.fit(train_sp)\n",
    "\n",
    "            mlflow.log_params(gs.best_params[\"rmse\"])\n",
    "            mlflow.log_metrics({\"rmse\": gs.best_score[\"rmse\"], \"mae\": gs.best_score[\"mae\"]})\n",
    "\n",
    "            algo = v[\"algo\"](**gs.best_params[\"rmse\"])\n",
    "            algo.fit(trainset)\n",
    "            predictions = algo.test(testset)\n",
    "            rmse = accuracy.rmse(predictions)\n",
    "            mae = accuracy.mae(predictions)\n",
    "\n",
    "            mlflow.log_metrics({\"rmse_test\": rmse, \"mae_test\": mae})\n",
    "\n",
    "            mlflow.sklearn.log_model(algo, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_train = algo.predict(trainset.build_testset())\n",
    "predictions_test = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy.rmse(predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea la matriz de predicciones\n",
    "n = len(users)\n",
    "m = len(products)\n",
    "recomendation = np.zeros((n, m))\n",
    "\n",
    "for k in users:\n",
    "    u = users.index(k)\n",
    "    for l in products:\n",
    "        i = products.index(l)\n",
    "        recomendation[u, i] = algo.predict(k, l, verbose=False)[3]\n",
    "\n",
    "recomendation = pd.DataFrame(recomendation, index=users, columns=products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "bsl_options = {\"method\": \"als\", \"n_epochs\": 5, \"reg_u\": 12, \"reg_i\": 5}\n",
    "\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "for trainset, testset in kf.split(data_sp):\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.fit(data_sp.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "cross_validate(algo, data_sp, measures=[\"RMSE\", \"MAE\"], cv=3, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data_sp, test_size=0.25)\n",
    "algo = BaselineOnly(bsl_options=bsl_options)\n",
    "predictions = algo.fit(trainset).test(testset)\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Iu(uid):\n",
    "    \"\"\"Return the number of items rated by given user\n",
    "    args:\n",
    "      uid: the id of the user\n",
    "    returns:\n",
    "      the number of items rated by the user\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ur[trainset.to_inner_uid(uid)])\n",
    "    except ValueError:  # user was not part of the trainset\n",
    "        return 0\n",
    "\n",
    "\n",
    "def get_Ui(iid):\n",
    "    \"\"\"Return number of users that have rated given item\n",
    "    args:\n",
    "      iid: the raw id of the item\n",
    "    returns:\n",
    "      the number of users that have rated the item.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return len(trainset.ir[trainset.to_inner_iid(iid)])\n",
    "    except ValueError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df = pd.DataFrame(predictions, columns=[\"uid\", \"iid\", \"rui\", \"est\", \"details\"])\n",
    "df[\"Iu\"] = df.uid.apply(get_Iu)\n",
    "df[\"Ui\"] = df.iid.apply(get_Ui)\n",
    "df[\"err\"] = abs(df.est - df.rui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Iu\", \"err\"]].plot(kind=\"scatter\", x=\"Iu\", y=\"err\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"err\"].plot(kind=\"hist\", bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Iu\")[\"err\"].min().plot(label=\"min\")\n",
    "df.groupby(\"Iu\")[\"err\"].max().plot(label=\"max\")\n",
    "df.groupby(\"Iu\")[\"err\"].mean().plot(label=\"mean\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"Iu\")[\"err\"].min().plot(label=\"min\")\n",
    "df.groupby(\"Iu\")[\"err\"].max().plot(label=\"max\")\n",
    "df.groupby(\"Iu\")[\"err\"].mean().plot(label=\"mean\")\n",
    "plt.xlim(0, 20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions = df[(df[\"err\"] <= 1.0)]\n",
    "worst_predictions = df[(df[\"err\"] > 1.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_predictions[\"Iu\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions[\"Iu\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_predictions.groupby(\"Iu\")[\"err\"].min().plot(label=\"min\")\n",
    "best_predictions.groupby(\"Iu\")[\"err\"].mean().plot(label=\"mean\")\n",
    "best_predictions.groupby(\"Iu\")[\"err\"].max().plot(label=\"max\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_predictions.groupby(\"Iu\")[\"err\"].min().plot(label=\"min\")\n",
    "worst_predictions.groupby(\"Iu\")[\"err\"].mean().plot(label=\"mean\")\n",
    "worst_predictions.groupby(\"Iu\")[\"err\"].max().plot(label=\"max\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(predictions, n=10):\n",
    "    # First map the predictions to each user.\n",
    "    top_n = {}\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        if uid in top_n:\n",
    "            top_n[uid].append((iid, est))\n",
    "        else:\n",
    "            top_n[uid] = [(iid, est)]\n",
    "    # Then sort the predictions for each user and retrieve the n highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = get_top_n(predictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
